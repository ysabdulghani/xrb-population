{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "instr = 'maxi'\n",
    "# instr = 'xrt'\n",
    "\n",
    "os.makedirs(f\"plots/{instr}\",exist_ok=True)\n",
    "\n",
    "# Define the pattern to match the CSV files\n",
    "file_pattern = '/disk/data/youssef/scripts/xrb-population/results_latest/'+instr+'_results/*.csv'\n",
    "csv_files = [file for file in glob(file_pattern) if \"full\" not in file]\n",
    "\n",
    "# csv_files = [file for file in csv_files if \"T0.3\" not in file]\n",
    "# csv_files = [file for file in csv_files if \"r0.7\" not in file]\n",
    " \n",
    "# Function to extract parameter values from filenames\n",
    "def extract_parameters(filename):\n",
    "    pattern = r'table_g(?P<g>\\d+\\.\\d+)_T(?P<T>\\d+\\.\\d+)_a(?P<a>\\d+\\.\\d+)_m(?P<m>\\d+\\.\\d+)_i(?P<i>\\d+\\.\\d+)_r(?P<r>\\d+\\.\\d+)_e(?P<e>\\d+\\.\\d+)\\.csv'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return {key: float(value) for key, value in match.groupdict().items()}\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# List to store summary statistics\n",
    "summary_data = []\n",
    "\n",
    "# Initialize an empty list to store distances\n",
    "distances = []\n",
    "\n",
    "# Initialize an empty list to store distances with non-available 'frac_uncert'\n",
    "na_distances = []\n",
    "\n",
    "# Initialize an empty list to all data\n",
    "all_data = []\n",
    "\n",
    "# Initialize a dictionary to store filenames with non-available 'd_fit'\n",
    "na_d_fit_files = []\n",
    "\n",
    "na_d_fit_params = []\n",
    "\n",
    "na_nH = []\n",
    "\n",
    "all_data_params= []\n",
    "\n",
    "# Process each file\n",
    "for file in csv_files:\n",
    "    parameters = extract_parameters(file)\n",
    "    if parameters:\n",
    "        try:\n",
    "            data = pd.read_csv(file)    \n",
    "            # Filter rows where the absolute fractional uncertainty is less than 0.5\n",
    "            \n",
    "            # filtered_data = data[abs(data['frac_uncert']) < 10]\n",
    "            \n",
    "            \n",
    "            # filtered_data2 = data[abs(data['frac_uncert']) < 0.5]\n",
    "            filtered_data2 = data[data['d_fit'].notna()]\n",
    "            \n",
    "            # Append the distances ('d') to the list\n",
    "            distances.extend(filtered_data2['d'].values)\n",
    "            na_data = data[data['d_fit'].isna()]\n",
    "            na_distances.extend(na_data['d'].values)\n",
    "            na_nH.extend(na_data['nH'].values)\n",
    "\n",
    "            all_data.append(data[['nH', 'd', 'frac_uncert','d_fit']])\n",
    "            all_data_params.append(parameters)\n",
    "\n",
    "            selected_data = data[data['d']==1]\n",
    "\n",
    "            # Check if 'd_fit' contains NaN and store filename if true\n",
    "            if selected_data['d_fit'].isna().any():\n",
    "                na_d_fit_files.append(os.path.basename(file))\n",
    "                # Extract parameters from the filename using regex\n",
    "                na_d_fit_params.append(parameters)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def exp_decay(x,a,b):\n",
    "    return b*np.exp(-a*x)\n",
    "\n",
    "def volume_density_exp_decay(x,L):\n",
    "    return (1/(2*(L**3)))*(x**2)*np.exp(-(x/L))\n",
    "\n",
    "n, bins,_ = plt.hist(distances, bins=50, edgecolor='black',density = True)\n",
    "\n",
    "print(n.sum()*(bins[1]-bins[0]))\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "xdata = bins[:-1] + ((bins[1:]-bins[:-1])/2) \n",
    "\n",
    "xdata = xdata[n>0]\n",
    "\n",
    "ydata = n[n>0]\n",
    "\n",
    "popt, pcov = curve_fit(volume_density_exp_decay, xdata, ydata)\n",
    "\n",
    "# distances_numpy = np.array(distances)\n",
    "# kde = KernelDensity(kernel='gaussian', bandwidth=5).fit(distances_numpy.reshape(-1, 1))\n",
    "distances_plot = np.linspace(0.215, 40, 3979)\n",
    "# density = np.exp(kde.score_samples(distances_plot.reshape(-1, 1)))\n",
    "\n",
    "density = volume_density_exp_decay(distances_plot,*popt)\n",
    "\n",
    "# density = density/(density.sum()*(distances_plot[1]-distances_plot[0]))\n",
    "\n",
    "print(density.sum()*(distances_plot[1]-distances_plot[0]))\n",
    "\n",
    "print((distances_plot[1]-distances_plot[0]))\n",
    "\n",
    "plt.plot(xdata,ydata)\n",
    "plt.plot(distances_plot,density)\n",
    "plt.xlabel('Distance (d)')\n",
    "plt.ylabel('Density')\n",
    "# plt.yscale('log')\n",
    "# plt.title('Histogram of Distances with Absolute Fractional Uncertainty < 0.5 (Aggregated)')\n",
    "np.save(f'{instr}_density.npy',density)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine distances and na_distances into a list of datasets\n",
    "data = [distances, na_distances]\n",
    "\n",
    "# Plot the histogram of the aggregated distances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data, bins=50, edgecolor='black', stacked=True, label=['Distances', 'Non-Available Distances'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Distance (d)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Stacked Histogram of Distances')\n",
    "\n",
    "# Add grid and legend\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the aggregated distances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(distances, bins=50, edgecolor='black')\n",
    "plt.hist(na_distances, bins=50, edgecolor='red', alpha=0.5, label='Non-Available Distances')\n",
    "plt.xlabel('Distance (d)')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.yscale('log')\n",
    "plt.title('Histogram of Distances with Absolute Fractional Uncertainty < 0.5 (Aggregated)')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the aggregated distances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(na_distances, bins=50, edgecolor='black')\n",
    "plt.xlabel('Distance (d)')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Distances with Absolute Fractional Uncertainty < 0.5 (Aggregated)')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the data into a single DataFrame\n",
    "aggregated_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Create a pivot table for the heatmap\n",
    "heatmap_data = aggregated_data.pivot_table(index='nH', columns='d', values='d_fit', aggfunc=np.median)\n",
    "\n",
    "# Sort the index (nH) in ascending order\n",
    "heatmap_data = heatmap_data.sort_index(ascending=False)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, cmap='viridis', annot=True, cbar_kws={'label': 'd_fit'})\n",
    "plt.xlabel('Distance (d)') \n",
    "plt.ylabel('nH')\n",
    "plt.title('Heatmap of nH vs Distance with Fractional Uncertainty as Height')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group the data by 'nH' and 'd'\n",
    "grouped_data = aggregated_data.groupby(['nH', 'd'])\n",
    "\n",
    "# Define unique values of nH and d for the grid layout\n",
    "nH_values = sorted(aggregated_data['nH'].unique(), reverse=True)\n",
    "d_values = sorted(aggregated_data['d'].unique())\n",
    "\n",
    "# Adjust figure size to fit MNRAS page dimensions\n",
    "fig_width = 6.974  # MNRAS page width in inches\n",
    "fig_height_per_row = 1.8  # Adjusted height per row\n",
    "fig_height = fig_height_per_row * len(nH_values)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    len(nH_values), len(d_values),\n",
    "    figsize=(fig_width, fig_height),\n",
    "    sharex=True, sharey=True,  # Share x and y axes\n",
    "    gridspec_kw={'wspace': 0, 'hspace': 0}  # Overlap axes\n",
    ")\n",
    "\n",
    "# Get global y-axis limits\n",
    "all_d_fit_values = aggregated_data['d_fit']\n",
    "# ymin, ymax = all_d_fit_values.min(), all_d_fit_values.max()\n",
    "\n",
    "# Iterate through each nH and d to plot the distribution at each grid cell\n",
    "for i, nH in enumerate(nH_values):\n",
    "    for j, d in enumerate(d_values):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # Get the distribution of d_fit for each combination of nH and d\n",
    "        subset = grouped_data.get_group((nH, d))['d_fit'] if (nH, d) in grouped_data.groups else []\n",
    "        \n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        if len(subset) > 0:\n",
    "            sns.violinplot(y=subset, ax=ax, inner=\"point\", color=\"grey\", linewidth=0.5)\n",
    "        \n",
    "        # Reduce grid lines to only major ticks on the y-axis\n",
    "        ax.grid(True, axis='y', which='major', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Set consistent y-axis limits\n",
    "        # ax.set_ylim(ymin, ymax)\n",
    "\n",
    "        # Remove the default y-label\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "        # Horizontal line for reference\n",
    "        ax.axhline(y=d_values[j], color=\"black\", linestyle='-', linewidth=1.2)\n",
    "\n",
    "        # Set titles and labels\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"$D = {d}$ kpc\", fontsize=7, pad=5)  # Font size adjusted\n",
    "        # if j == 0:\n",
    "        #     ax.set_ylabel(f\"$N_H = {nH}$\", fontsize=7, labelpad=2)  # Reduced padding\n",
    "\n",
    "        if j == 0:  # Only add label once per row\n",
    "            ax.text(0.05, 0.95, f\"Input $N_H$ = {nH}\", transform=ax.transAxes,\n",
    "                    fontsize=5, verticalalignment='top', horizontalalignment='left',\n",
    "                    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.2',linewidth=0.3))\n",
    "\n",
    "        # Add x-axis labels for the bottom row\n",
    "        if i == len(nH_values) - 1:\n",
    "            ax.set_xlabel(f\"$D = {d}$ kpc\", fontsize=7)\n",
    "            ax.tick_params(axis='x', rotation=45)  # Rotate x-labels\n",
    "\n",
    "        # Customize ticks\n",
    "        ax.tick_params(axis='both', which='major', labelsize=6, length=5, width=0.8)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=6, length=3, width=0.5)\n",
    "\n",
    "# Shared ylabel positioned closer to the subplots\n",
    "fig.text(0.015, 0.5, 'Estimated $D$ (kpc)', va='center', rotation='vertical', fontsize=10)\n",
    "\n",
    "# Adjust layout to ensure no text overlap\n",
    "plt.tight_layout(pad=0.8, rect=[0.03, 0.05, 1, 0.95])\n",
    "\n",
    "# Save the figure as a high-resolution PDF\n",
    "plt.savefig(f\"plots/{instr}/2d_violin_plot_{instr}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Define the parameter labels with proper LaTeX formatting and units\n",
    "parameter_labels = {\n",
    "    'g': r\"$\\Gamma$\",                        # Gamma (no unit label)\n",
    "    'T': r\"$T$ (keV)\",                       # Temperature in keV\n",
    "    'a': r\"$a$\",                              # Spin parameter (no unit label)\n",
    "    'm': r\"$M_{\\odot}$\",                     # Mass in solar masses\n",
    "    'i': r\"$i$ (degrees)\",                   # Inclination in degrees\n",
    "    'r': r\"Disk-to-total ratio\",             # Disk to total ratio (no unit label)\n",
    "    'e': r\"Exposure (sec)\"                   # Exposure in seconds\n",
    "}\n",
    "\n",
    "# Step 1: Attach parameters to each entry in all_data using all_data_params\n",
    "all_data_with_params = []\n",
    "for data_df, params in zip(all_data, all_data_params):  # Match each dataset with its parameters\n",
    "    # Repeat the parameter dictionary for each row in the corresponding data_df\n",
    "    params_df = pd.DataFrame([params] * len(data_df))\n",
    "    # Concatenate data and parameters\n",
    "    data_with_params = pd.concat([data_df.reset_index(drop=True), params_df.reset_index(drop=True)], axis=1)\n",
    "    all_data_with_params.append(data_with_params)\n",
    "\n",
    "# Step 2: Concatenate all entries into a single DataFrame\n",
    "all_data_flat = pd.concat(all_data_with_params, ignore_index=True)\n",
    "\n",
    "# Define the parameters to aggregate by\n",
    "parameters = ['g', 'T', 'a', 'm', 'i', 'r', 'e']\n",
    "\n",
    "# Step 3: Loop through each parameter and create violin plots\n",
    "for param in parameters:\n",
    "    # Get unique values for the current parameter and distance\n",
    "    param_values = sorted(all_data_flat[param].unique())\n",
    "    d_values = sorted(all_data_flat['d'].unique())\n",
    "\n",
    "    # Create subplots for the current parameter\n",
    "    fig, axes = plt.subplots(\n",
    "        len(param_values), 1,\n",
    "        figsize=(3.3, len(param_values) * 1.5),  # Single-column layout\n",
    "        sharex=True\n",
    "    )\n",
    "\n",
    "    # Iterate through each parameter value and plot distributions\n",
    "    for i, (ax, val) in enumerate(zip(axes, param_values)):\n",
    "        # Filter the data for the current parameter value\n",
    "        subset = all_data_flat.loc[all_data_flat[param] == val].copy()\n",
    "\n",
    "        if not subset.empty:\n",
    "            subset['d'] = subset['d'].astype(str)  # Convert 'd' to string for categorical x-axis\n",
    "            ax.set_yscale('log')  # Use log scale for y-axis\n",
    "            palette = sns.color_palette('colorblind', len(d_values))  # Colorblind-friendly palette\n",
    "            sns.violinplot(\n",
    "                data=subset,\n",
    "                x='d',\n",
    "                y='d_fit',\n",
    "                ax=ax,\n",
    "                hue='d',  # Assign hue to the same as x-axis\n",
    "                inner=None,  # No internal marks\n",
    "                palette=palette,\n",
    "                linewidth=0.3,  # Reduced line width for clarity\n",
    "                legend=False  # Suppress legend\n",
    "            )\n",
    "\n",
    "            # Dynamically calculate the true x-axis limits after padding\n",
    "            x_limits = ax.get_xlim()\n",
    "            x_left = x_limits[0]  # True left edge of the axis\n",
    "            for d_idx, d_value in enumerate(d_values):\n",
    "                # Get subset of data for the current `d_value`\n",
    "                data_d_value = subset.loc[subset['d'] == str(d_value), 'd_fit']\n",
    "                if not data_d_value.empty:\n",
    "                    x_max = d_idx + 0.3  # Slightly after the violin's center\n",
    "                    ax.plot([x_left, x_max], [d_value, d_value], color=palette[d_idx], linestyle='-', linewidth=0.5)\n",
    "\n",
    "        # Add titles using parameter_labels\n",
    "        ax.set_title(f\"{parameter_labels[param]} = {val}\", fontsize=7, pad=2)\n",
    "        ax.set_ylabel(\"Estimated $D$ (kpc)\", fontsize=7, labelpad=2)\n",
    "        ax.grid(True, which='major', linestyle=':', linewidth=0.3)\n",
    "\n",
    "        # Adjust tick size to match label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=7, length=3, width=0.3)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=7, length=2, width=0.3)\n",
    "\n",
    "        # Adjust the y-axis ticks explicitly for log scaling\n",
    "        ax.yaxis.set_major_locator(ticker.LogLocator(base=10.0, numticks=5))  # Max 5 major ticks\n",
    "        ax.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs=\"auto\", numticks=10))  # Minor ticks\n",
    "        ax.set_xlim(x_limits)\n",
    "\n",
    "    # Add x-axis label for the bottom plot\n",
    "    axes[-1].set_xlabel(\"$D$ (kpc)\", fontsize=7)\n",
    "\n",
    "    # Adjust layout to ensure no overlaps and save the figure\n",
    "    plt.tight_layout(pad=0.8)\n",
    "    plt.savefig(f\"plots/{instr}/{param}_violin_plot_{instr}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each parameter in files that have 'd_fit' = NaN\n",
    "plt.figure(figsize=(15, 10))\n",
    "parameter_names = ['g', 'T', 'a', 'm', 'i', 'r', 'e']\n",
    "\n",
    "# Iterate over parameters and plot histograms in a 2x3 layout\n",
    "for idx, param_name in enumerate(parameter_names[:7]):  # Only using the first 6 parameters for the 2x3 layout\n",
    "    values = [params[param_name] for params in na_d_fit_params if param_name in params]\n",
    "    plt.subplot(3, 3, idx + 1)\n",
    "    plt.hist(values, bins=15, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram for Parameter: {param_name} (Files with d_fit = NaN)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bin edges\n",
    "x_bins = [1, 2, 3, 4, 5, 6, 8, 12, 18, 27]\n",
    "y_bins = [0, 0.5,1, 6.7, 10]\n",
    "\n",
    "# Plot a 2D histogram for 'nH' and 'd' of non-available distances\n",
    "plt.figure(figsize=(12, 6))\n",
    "hist, x_edges, y_edges, im = plt.hist2d(na_distances, na_nH, bins=(x_bins, y_bins), cmap='viridis')\n",
    "plt.ylabel('nH')\n",
    "plt.xlabel('Distance (d)')\n",
    "plt.colorbar(label='Count')\n",
    "plt.title('2D Histogram of nH and Distance for Non-Available Distances')\n",
    "\n",
    "# Annotate counts on the cells\n",
    "for i in range(len(x_edges) - 1):\n",
    "    for j in range(len(y_edges) - 1):\n",
    "        count = hist[i, j]\n",
    "        # if count > 0:  # Only annotate non-empty bins\n",
    "        plt.text((x_edges[i] + x_edges[i + 1]) / 2,\n",
    "                    (y_edges[j] + y_edges[j + 1]) / 2,\n",
    "                    int(count),\n",
    "                    ha='center', va='center', color='white')\n",
    "                    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
